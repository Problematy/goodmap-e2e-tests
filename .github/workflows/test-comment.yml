name: Post E2E Test Results

on:
  workflow_run:
    workflows: ["E2E Tests"]
    types:
      - completed

permissions:
  contents: read
  pull-requests: write

jobs:
  comment:
    runs-on: ubuntu-latest
    if: github.event.workflow_run.conclusion != 'cancelled'
    steps:
      - name: Download test results
        id: download
        uses: actions/github-script@v7
        with:
          script: |
            const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: ${{ github.event.workflow_run.id }}
            });

            const matchArtifact = artifacts.data.artifacts.find(artifact => artifact.name === 'test-results');
            if (!matchArtifact) {
              console.log('No test-results artifact found - workflow may have failed before uploading artifacts');
              core.setOutput('artifact-found', 'false');
              return;
            }
            core.setOutput('artifact-found', 'true');

            const download = await github.rest.actions.downloadArtifact({
              owner: context.repo.owner,
              repo: context.repo.repo,
              artifact_id: matchArtifact.id,
              archive_format: 'zip'
            });

            const fs = require('fs');
            fs.writeFileSync('${{ github.workspace }}/test-results.zip', Buffer.from(download.data));

      - name: Extract artifacts
        if: steps.download.outputs.artifact-found == 'true'
        run: |
          unzip -o test-results.zip || echo "No artifact to extract"

      - name: Read PR metadata
        if: steps.download.outputs.artifact-found == 'true'
        id: pr-metadata
        run: |
          if [ -f tmp/pr-number.txt ]; then
            echo "pr-number=$(cat tmp/pr-number.txt)" >> $GITHUB_OUTPUT
            echo "pr-sha=$(cat tmp/pr-sha.txt)" >> $GITHUB_OUTPUT
          else
            echo "No PR metadata found - not a PR build"
            echo "pr-number=" >> $GITHUB_OUTPUT
          fi

      - name: Post comment with test results
        if: steps.pr-metadata.outputs.pr-number != ''
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            const prNumber = parseInt('${{ steps.pr-metadata.outputs.pr-number }}');
            const prSha = '${{ steps.pr-metadata.outputs.pr-sha }}';
            const conclusion = '${{ github.event.workflow_run.conclusion }}';
            const runUrl = '${{ github.event.workflow_run.html_url }}';

            let comment = '## ğŸ§ª E2E Test Results\n\n';

            // Add workflow status
            if (conclusion === 'success') {
              comment += 'âœ… **Status**: All tests passed\n\n';
            } else if (conclusion === 'failure') {
              comment += 'âŒ **Status**: Tests failed\n\n';
            } else {
              comment += `âš ï¸ **Status**: ${conclusion}\n\n`;
            }

            comment += `ğŸ“Š [View full workflow run](${runUrl})\n`;
            comment += `ğŸ”— Commit: \`${prSha.substring(0, 7)}\`\n\n`;

            // Add detailed performance metrics if available
            if (fs.existsSync('cypress/results/stress-test-perf.json')) {
              const perfData = JSON.parse(fs.readFileSync('cypress/results/stress-test-perf.json', 'utf8'));

              comment += '## ğŸ“Š E2E Stress Test Performance\n\n';

              // Check for errors
              if (perfData.error) {
                comment += `âŒ **Status**: ERROR - ${perfData.error}\n\n`;
              } else if (perfData.numRuns < (perfData.expectedRuns || perfData.numRuns)) {
                comment += `âš ï¸ **Status**: INCOMPLETE - Only ${perfData.numRuns}/${perfData.expectedRuns} runs completed\n\n`;
              } else if (perfData.passed) {
                comment += `âœ… **Status**: PASSED (${perfData.maxTime}ms max < ${perfData.maxAllowed}ms limit)\n\n`;
              } else {
                comment += `âŒ **Status**: FAILED (${perfData.maxTime}ms max >= ${perfData.maxAllowed}ms limit)\n\n`;
              }

              // Summary table (only if we have data)
              if (perfData.numRuns > 0) {
                comment += '| Metric | Value |\n';
                comment += '|--------|-------|\n';
                comment += `| **Average Time** | ${perfData.avgTime}ms |\n`;
                comment += `| **Minimum Time** | ${perfData.minTime}ms |\n`;
                comment += `| **Maximum Time** | ${perfData.maxTime}ms |\n`;
                comment += `| **Completed Runs** | ${perfData.numRuns}${perfData.expectedRuns ? '/' + perfData.expectedRuns : ''} |\n\n`;

                // Individual run times
                if (perfData.runTimes && perfData.runTimes.length > 0) {
                  comment += '<details>\n<summary>ğŸ“ˆ Individual Run Times</summary>\n\n';
                  comment += '| Run | Time (ms) |\n';
                  comment += '|-----|----------|\n';
                  perfData.runTimes.forEach(run => {
                    comment += `| Run ${run.run} | ${run.time}ms |\n`;
                  });
                  comment += '\n</details>\n';
                }
              }
            } else {
              comment += '## âš ï¸ E2E Stress Test Results\n\n';
              comment += 'Performance data not found. See workflow logs for details.\n';
            }

            // Post comment to PR
            await github.rest.issues.createComment({
              issue_number: prNumber,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

            console.log(`âœ“ Posted test results to PR #${prNumber}`);
