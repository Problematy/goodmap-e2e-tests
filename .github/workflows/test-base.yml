on:
  workflow_call:
    inputs:
      goodmap-version:
        required: true
        type: string
      goodmap-frontend-version:
        required: true
        type: string
      goodmap-e2e-version:
        required: true
        type: string
      calling-repo:
        description: 'Which repository is calling this workflow (goodmap-e2e-tests, goodmap, or goodmap-frontend)'
        required: false
        type: string
      e2e-tests-path:
        description: 'Path to e2e-tests repository (leave empty to auto-detect based on calling-repo)'
        required: false
        type: string
        default: '.'
      goodmap-path:
        description: 'Path to goodmap repository (leave empty to auto-detect based on calling-repo)'
        required: false
        type: string
        default: 'goodmap'
      goodmap-frontend-path:
        description: 'Path to goodmap-frontend repository (leave empty to auto-detect based on calling-repo)'
        required: false
        type: string
        default: 'goodmap-frontend'
      goodmap-config-path:
        description: 'Path to goodmap configuration file for e2e tests'
        required: false
        type: string
        default: e2e_test_config.yml

permissions:
  contents: read
  pull-requests: write

jobs:
  e2e-tests:
    name: E2E tests
    runs-on: ubuntu-latest
    steps:
    - name: Checkout calling repository
      uses: actions/checkout@v4
      with:
        submodules: ${{ inputs.calling-repo == 'goodmap' && 'true' || 'false' }}

    - name: Checkout e2e-tests repository
      if: inputs.calling-repo != 'goodmap-e2e-tests'
      uses: actions/checkout@v4
      with:
        path: ${{ inputs.e2e-tests-path }}
        repository: problematy/goodmap-e2e-tests
        ref: ${{ inputs.goodmap-e2e-version }}

    - name: Checkout goodmap repository
      if: inputs.calling-repo != 'goodmap'
      uses: actions/checkout@v4
      with:
        path: ${{ inputs.goodmap-path }}
        repository: problematy/goodmap
        submodules: 'true'
        ref: ${{ inputs.goodmap-version }}

    - name: Checkout goodmap-frontend repository
      if: inputs.calling-repo != 'goodmap-frontend'
      uses: actions/checkout@v4
      with:
        repository: problematy/goodmap-frontend
        ref: ${{ inputs.goodmap-frontend-version }}
        path: ${{ inputs.goodmap-frontend-path }}

    - name: Install frontend dependencies
      working-directory: ${{ inputs.goodmap-frontend-path }}
      run: npm install

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.10"

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: 'latest'

    - name: Install python dependencies
      working-directory: ${{ inputs.goodmap-path }}
      run: poetry install

    - name: Install e2e dependencies
      working-directory: ${{ inputs.e2e-tests-path }}
      run: npm install

    - name: Start frontend server
      working-directory: ${{ inputs.goodmap-frontend-path }}
      run: |
        make serve &
        echo $! > /tmp/frontend.pid
        sleep 3

    - name: Start backend for e2e tests
      working-directory: ${{ inputs.goodmap-path }}
      env:
        CONFIG_PATH: ${{ inputs.goodmap-config-path }}
        GOODMAP_PATH: ${{ github.workspace }}/${{ inputs.goodmap-path }}
      run: |
        make run-e2e-goodmap > /tmp/backend-e2e.log 2>&1 &
        echo $! > /tmp/backend-e2e.pid
        sleep 5
        # Check if backend started successfully
        if ! kill -0 $(cat /tmp/backend-e2e.pid) 2>/dev/null; then
          echo "Backend failed to start. Log:"
          cat /tmp/backend-e2e.log
          exit 1
        fi
        echo "Backend started with PID $(cat /tmp/backend-e2e.pid)"

    - name: Run e2e tests
      working-directory: ${{ inputs.e2e-tests-path }}
      env:
        NO_COLOR: 1
      run: |
        make e2e-tests | tee /tmp/e2e-tests-output.txt

    - name: Stop backend for e2e tests
      if: always()
      run: |
        if [ -f /tmp/backend-e2e.pid ]; then
          kill $(cat /tmp/backend-e2e.pid) 2>/dev/null || true
        fi
        pkill -f "flask.*e2e_test_config" || true
        sleep 1

    - name: Add e2e test results to summary
      if: always()
      run: |
        if [ -f /tmp/e2e-tests-output.txt ]; then
          echo "## âœ… Basic E2E Tests Completed" >> $GITHUB_STEP_SUMMARY
          echo "See workflow logs for details" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Generate e2e stress test data
      working-directory: ${{ inputs.e2e-tests-path }}
      run: make e2e-stress-tests-generate-data

    - name: Start backend for stress tests
      working-directory: ${{ inputs.e2e-tests-path }}
      env:
        CONFIG_PATH: e2e_stress_test_config.yml
        GOODMAP_PATH: ${{ github.workspace }}/${{ inputs.goodmap-path }}
      run: |
        make run-e2e-stress-env > /tmp/backend-stress.log 2>&1 &
        echo $! > /tmp/backend-stress.pid
        sleep 5
        # Check if backend started successfully
        if ! kill -0 $(cat /tmp/backend-stress.pid) 2>/dev/null; then
          echo "Backend failed to start. Log:"
          cat /tmp/backend-stress.log
          exit 1
        fi
        echo "Backend started with PID $(cat /tmp/backend-stress.pid)"

    - name: Run e2e stress tests
      working-directory: ${{ inputs.e2e-tests-path }}
      env:
        NO_COLOR: 1
      run: |
        make e2e-stress-tests | tee /tmp/e2e-stress-tests-output.txt

    - name: Stop backend for stress tests
      if: always()
      run: |
        if [ -f /tmp/backend-stress.pid ]; then
          kill $(cat /tmp/backend-stress.pid) 2>/dev/null || true
        fi
        pkill -f "flask.*e2e_stress_test_config" || true
        sleep 1

    - name: Add stress test results to summary
      if: always()
      run: |
        PERF_FILE="${{ github.workspace }}/${{ inputs.e2e-tests-path }}/cypress/results/stress-test-perf.json"

        if [ -f "$PERF_FILE" ]; then
          echo "## ðŸ“Š E2E Stress Test Performance" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Parse and display performance metrics
          AVG=$(jq -r '.avgTime' "$PERF_FILE")
          MIN=$(jq -r '.minTime' "$PERF_FILE")
          MAX=$(jq -r '.maxTime' "$PERF_FILE")
          LIMIT=$(jq -r '.maxAllowed' "$PERF_FILE")
          PASSED=$(jq -r '.passed' "$PERF_FILE")
          RUNS=$(jq -r '.numRuns' "$PERF_FILE")

          if [ "$PASSED" = "true" ]; then
            echo "âœ… **Status**: PASSED (${MAX}ms max < ${LIMIT}ms limit)" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Status**: FAILED (${MAX}ms max >= ${LIMIT}ms limit)" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Average Time** | ${AVG}ms |" >> $GITHUB_STEP_SUMMARY
          echo "| **Minimum Time** | ${MIN}ms |" >> $GITHUB_STEP_SUMMARY
          echo "| **Maximum Time** | ${MAX}ms |" >> $GITHUB_STEP_SUMMARY
          echo "| **Number of Runs** | ${RUNS} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Individual run times
          echo "<details>" >> $GITHUB_STEP_SUMMARY
          echo "<summary>ðŸ“ˆ Individual Run Times</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Run | Time (ms) |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|----------|" >> $GITHUB_STEP_SUMMARY
          jq -r '.runTimes[] | "| Run \(.run) | \(.time)ms |"' "$PERF_FILE" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY
        else
          echo "## âš ï¸ E2E Stress Test Results" >> $GITHUB_STEP_SUMMARY
          echo "Performance data not found" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Save PR metadata for comment workflow
      if: always() && github.event.pull_request.number
      run: |
        echo ${{ github.event.pull_request.number }} > /tmp/pr-number.txt
        echo ${{ github.event.pull_request.head.sha }} > /tmp/pr-sha.txt

    - name: Upload test results as artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results
        path: |
          /tmp/e2e-tests-output.txt
          /tmp/e2e-stress-tests-output.txt
          /tmp/pr-number.txt
          /tmp/pr-sha.txt
          ${{ inputs.e2e-tests-path }}/cypress/results/stress-test-perf.json
        retention-days: 1
        if-no-files-found: ignore

    - name: Stop frontend server
      if: always()
      run: |
        if [ -f /tmp/frontend.pid ]; then
          kill $(cat /tmp/frontend.pid) 2>/dev/null || true
        fi
